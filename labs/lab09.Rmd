---
title: "Lab 9"
author: "Mohammed Z Hasan"
output: pdf_document
---

#YARF

For the next couple of labs, I want you to make some use of a package I wrote that offers convenient and flexible tree-building and random forest-building. Make sure you have a JDK installed first

https://www.oracle.com/java/technologies/downloads/

Then try to install rJava

```{r}
options(java.parameters = "-Xmx4000m")
pacman::p_load(rJava)
.jinit()
```

If you have error, messages, try to google them. Everyone has trouble with rJava!

If that worked, please try to run the following which will install YARF from my github:

```{r}
if (!pacman::p_isinstalled(YARF)){
  pacman::p_install_gh("kapelner/YARF/YARFJARs", ref = "dev")
  pacman::p_install_gh("kapelner/YARF/YARF", ref = "dev", force = TRUE)
}
pacman::p_load(YARF)
```

Please try to fix the error messages (if they exist) as best as you can. I can help on slack.

#Data Munging: a realistic exercise

This lab exercise may be the most important lab of the semester in terms of real-world experience and "putting it all together". We will be constructing a data frame which will then get passed on to the model-building. So this emulates the pre-steps necessary to get to the point where we assume we're at in this class.

We will be joining three datasets in an effort to make a design matrix that predicts if a bill will be paid on time. Clean up and load up the three files. Then I'll rename a few features and then we can examine the data frames.

Make sure you set the directory of RStudio to the directory where this file lives and make sure you download the bills_dataset folder from github (you can do this via `git pull` and then copying that directory over).

```{r}
#setwd(...)
rm(list = ls())
pacman::p_load(tidyverse, magrittr, data.table, R.utils)
bills = fread("bills_dataset/bills.csv.bz2")
payments = fread("bills_dataset/payments.csv.bz2")
discounts = fread("bills_dataset/discounts.csv.bz2")
setnames(bills, "amount", "tot_amount")
setnames(payments, "amount", "paid_amount")
skimr::skim(bills)
skimr::skim(payments)
skimr::skim(discounts)
```

The unit we care about is the bill. The y metric we care about will be "paid in full" which is 1 if the company paid their total amount (we will generate this y metric later).

Since this is the response, we would like to construct the very best design matrix in order to predict y.

First, join the three datasets in an intelligent way. You will need to examine the datasets beforehand.

```{r}
bills_and_payments = left_join(bills,payments,by = join_by("id" == "bill_id"))
bills_and_payments_and_discounts = left_join(bills_and_payments,discounts,by = join_by("discount_id" == "id"))
```

Now create the binary response metric `paid_in_full` as the last column and create the beginnings of a design matrix `bills_data`. Ensure the unit / observation is bill i.e. each row should be ONE bill ONLY! 

```{r}
#in dplyer select certain rows 
bills_and_payments_and_discounts %>%
  filter((!is.na(transaction_date ) & transaction_date <= due_date) | is.na(transaction_date ))
bills_and_payments_and_discounts %>%
  group_by(id) %>%
  mutate (payment_total = sum(paid_amount))
bills_and_payments_and_discounts %>%
  mutate(payment_total = if_else(is.na(payment_total),0,payment_total))
bills_and_payments_and_discounts %>%
  mutate(paid_in_full = as.numeric(payment_total >= tot_amount))
bills_and_payments_and_discounts = bills_and_payments_and_discounts %>%
  group_by(id) %>%
  slice(1)
table(bills_and_payments_and_discounts$paid_in_full)
```

How should you add features from transformations (called "featurization")? What data type(s) should they be? Make some features below if you think of any useful ones. Name the columns appropriately so another data scientist can easily understand what information is in your variables. Make sure missingness (if in a categorical variable) is treated as a legal level of that variable. Make sure the response variable is there too in the final data frame.

```{r}
bills_and_payments_and_discounts = bills_and_payments_and_discounts %>% mutate(due_date_as_integer = as.integer(due_date)) 
#do customer id's into factor for common customers > 10 otherwise "other" 
#convert discount id to fdactor if number of discount id's is > 10. Drop all other columns from discount table 
bills_and_payments_and_discounts = bills_and_payments_and_discounts %>% 
  select(-id.y, 
         -id, 
         -due_date, 
         -invoice_date, 
         -customer_id, 
         -discount_id, 
         -paid_amount, 
         -transaction_date, 
         -num_days, 
         -pct_off, 
         -days_until_discount, 
         -payment_total, 
         -payment_at_least_one_month_before_due_date) bills_and_payments_and_discounts
```


# Regression Trees

You can use the `YARF` package if it works, otherwise, use the `randomForest` package (the canonical R package for this algorithm).

Let's take a look at a simulated sine curve. Below is the code for the data generating process:

```{r}
rm(list = ls())
n_train = 500
sigma = 0.3
x_min = 0
x_max = 10

f_x = function(x){sin(x)}
x_train = runif(n_train, x_min, x_max)
y_train = f_x(x_train) + rnorm(n_train, 0, sigma)
```

Plot an example dataset of size 500:

```{r}
library(ggplot2)

n_test = 500

x_test = runif(n_test, x_min, x_max)
y_test = f_x(x_test) + rnorm(n_test, 0, sigma)

test_data = data.frame(x = x_test, y = y_test)

ggplot(test_data, aes(x = x, y = y)) +
  geom_point(alpha = 0.5, color = "red") +  # Points with slight transparency
  geom_line(data = data.frame(x = sort(x_test), y = f_x(sort(x_test))), color = "blue") +
  theme_minimal() +
  ggtitle("Test Data: Sine Curve with Noise") +
  xlab("X") +
  ylab("Y")
```

Create a test set of size 500 from this data generating process:

```{r}
ggplot(test_data, aes(x = x, y = y)) +
  geom_point(color = "red", alpha = 0.5) +  # Display the noisy data points
  geom_line(data = data.frame(x = sort(x_test), y = f_x(sort(x_test))), color = "blue") +
  theme_minimal() +
  ggtitle("Test Dataset: Sine Curve with Noise") +
  xlab("X value") +
  ylab("Y value (Noisy Sine)")
```

Locate the optimal node size hyperparameter for the regression tree model. I believe you can use `randomForest` here by setting `ntree = 1`, `replace = FALSE`, `sampsize = n` (`mtry` is already set to be 1 because there is only one feature) and then you can set `nodesize`. Plot nodesize by out of sample s_e. Plot.

```{r}
pacman::p_load(randomForest)
library(randomForest)
library(ggplot2)

node_sizes = seq(5, 100, by = 5)
results = data.frame(NodeSize = integer(), OOS_SE = double())

# Loop over node sizes
for (ns in node_sizes) {
  model = randomForest(x = data.frame(x = x_train), y = y_train, 
                       ntree = 1, replace = FALSE, sampsize = n_train, mtry = 1, 
                       nodesize = ns)
  predictions = predict(model, newdata = data.frame(x = x_test))
  oos_se = mean((predictions - y_test)^2)
  results = rbind(results, data.frame(NodeSize = ns, OOS_SE = oos_se))
}

# Plotting nodesize vs out-of-sample squared error
ggplot(results, aes(x = NodeSize, y = OOS_SE)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  ggtitle("Effect of Node Size on Out-of-Sample Squared Error") +
  xlab("Node Size") +
  ylab("Out-of-Sample Squared Error")

```

Plot the regression tree model g(x) with the optimal node size.

```{r}
# for instance, use 20 to be the optimal node size (made it upo)
optimal_ns = 20

# Train the model with the optimal node size
optimal_model = randomForest(x = data.frame(x = x_train), y = y_train, 
                              ntree = 1, replace = FALSE, sampsize = n_train, 
                              mtry = 1, nodesize = optimal_ns)

# Generate a dense set of x values for plotting
x_plot = seq(x_min, x_max, length.out = 500)
y_plot_predictions = predict(optimal_model, newdata = data.frame(x = x_plot))

# Creating a data frame so we can plot using ggplot after
plot_data = data.frame(x = x_plot, Predicted = y_plot_predictions)

# Plotting what the model predicts
ggplot() +
  geom_point(aes(x = x_test, y = y_test), color = "red", alpha = 0.5, size = 1.5) +
  geom_line(data = plot_data, aes(x = x, y = Predicted), color = "blue", size = 1) +
  theme_minimal() +
  ggtitle(sprintf("Regression Tree Model Predictions with Node Size %s", optimal_ns)) +
  xlab("X value") +
  ylab("Predicted Y value")

```

Find the oosRMSE of this optimal-node-size model.

```{r}
optimal_model = randomForest(x = data.frame(x = x_train), y = y_train,
                              ntree = 1, replace = FALSE, sampsize = n_train,
                              mtry = 1, nodesize = optimal_ns)

# Predict the test set
predictions = predict(optimal_model, newdata = data.frame(x = x_test))

# Calculate the oosRMSE
oosRMSE = sqrt(mean((predictions - y_test)^2))

oosRMSE
```

Provide the bias-variance decomposition of this DGP fit with this model. It is a lot of code, but it is in the practice lectures. If your three numbers don't add up within two significant digits, increase your resolution.

```{r}
```

# Classification Trees

Let's get the letter recognition data from the `mlbench` package.

```{r}
rm(list = ls())
pacman::p_load(mlbench)
data(LetterRecognition, package = "mlbench")
n = nrow(LetterRecognition)
skimr::skim(LetterRecognition)
```

This dataset has 20,000 examples. Create a training-select-test split so that they each have 1,000 observations.

```{r}
train_idx = sample(1 : n, 1000)
select_idx = sample(setdiff(1 : n, train_idx), 1000)
test_idx = sample(setdiff(1 : n, c(train_idx, select_idx)), 1000)
letters_train = LetterRecognition[train_idx, ]
letters_select = LetterRecognition[select_idx, ]
letters_test = LetterRecognition[test_idx, ]
```

Find the optimal classification tree by using the model selection algorithm to optimize the nodesize hyperparameter. Use misclassification error as the performance metric.

```{r}
nodesizes = seq(1, 200, by = 10)
misclassification_errs = array(NA, length(nodesizes))
for (i in seq_along(nodesizes)) {
  fit = rpart(letter ~ ., data = letters_train, control = rpart.control(minsplit = nodesizes[i]))

  predictions = predict(fit, letters_select, type = "class")

  cm = confusionMatrix(table(predictions, letters_select$letter))
  misclassification_errs[i] <- 1 - cm$overall['Accuracy']  # Misclassification error is 1 - accuracy
}

optimal_index <- which.min(misclassification_errs)
optimal_nodesize <- nodesizes[optimal_index]
optimal_error <- misclassification_errs[optimal_index]
```

Plot the oos misclassification error by nodesize.

```{r}
ggplot(data.frame(nodesize = nodesizes, misclassification_error = misclassification_errs)) + 
  aes(x = nodesize, misclassification_error = misclassification_error) +
  geom_point() + 
  geom_line()
```

Construct the optimal classification tree on train and select sets. Then estimate generalization error. Save `y_hat_test` as we'll need it later.

```{r}
tree_mod_opt = rpart(letter ~ ., data = full_train_set, 
                      control = rpart.control(minsplit = optimal_nodesize))
```

Print out the top of the tree so we can have some level of interpretation to how the model g is predicting.

```{r}
illustrate_trees(tree_mod_opt, max_depth = 5, length_in_px_per_half_split = 30, open_file = TRUE)
```

Create a "confusion matrix". This means it shows every predicted level (which is a letter in our case) and every actual level. Here you'll see every type of error e.g. "P was predicted but the real letter is H", "M was predicted but the real letter is N" etc. This is really easy: one call to the `table` function is all you need.

```{r}
actual_labels = letters_test$letter

predicted_labels = factor(y_hat_test, levels = levels(actual_labels))

confusion_mat = table(Predicted = predicted_labels, Actual = actual_labels)

confusion_mat
```

Which errors are most prominent in this model?

The errors that are most prominent are specification errors




